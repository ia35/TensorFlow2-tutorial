{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_GPU_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFiYDqXINbVIQm//Ydvvsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ia35/TensorFlow2-tutorial/blob/master/MNIST_GPU_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuEFmGr_nzCS",
        "colab_type": "text"
      },
      "source": [
        "[![](http://bec552ebfe.url-de-test.ws/ml/buttonBackProp.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYFC_N3Dn3cA",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)\n",
        "\n",
        "Le logo BackProp est présenté chaque fois qu'un point important doit être signalé"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFsnsgydqJ_t",
        "colab_type": "text"
      },
      "source": [
        "Cet exercice présente une classfication MNIST, en mode d'exécution CPU/GPU/TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apNuM46TpX0c",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"teal\">Mode d'exécution</font>\n",
        "\n",
        "Assurez-vous que le mode d'exécution est celui que vous voulez (GPU/TPU/CPU) \n",
        "\n",
        "(menu Exécution/Modifiez le type d'exécution/Accélérateur matériel)\n",
        "\n",
        "Commencez en mode CPU (none)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgfMF4W3qFL4",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"teal\">Note</font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rv34HYDtDaYM",
        "colab_type": "code",
        "outputId": "28ecd85d-29dc-406d-b966-956ecd3429a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Tensorflow version 2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHS5YDZb7VXO",
        "colab_type": "text"
      },
      "source": [
        "Tout d'abord on exécute en mode CPU, puis GPU puis TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL3zv2S3qlcJ",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nztGGSeqnGx",
        "colab_type": "text"
      },
      "source": [
        "N'exécutez les lignes suivantes qu'en mode TPU :\n",
        "\n",
        "- tf.keras.backend.set_floatx('float32')\n",
        "- AUTO = tf.data.experimental.AUTOTUNE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkixpVLYsyPQ",
        "colab_type": "text"
      },
      "source": [
        "En mode TPU, il faut que les data soit en float"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9cHfpCgrJdF",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"orange\">backend.set_floatx</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAoTieoLrAco",
        "colab_type": "text"
      },
      "source": [
        "tf.keras.backend.[set_floatx](https://www.tensorflow.org/api_docs/python/tf/keras/backend/set_floatx)\n",
        "\n",
        "Sets the default float type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5l5dXDlrtPM",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"orange\">tf.data.experimental.AUTOTUNE</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euvEOjVhrjWS",
        "colab_type": "text"
      },
      "source": [
        "The tf.data API provides the tf.data.Dataset.prefetch transformation. It can be used to decouple the time when data is produced from the time when data is consumed. In particular, the transformation uses a background thread and an internal buffer to prefetch elements from the input dataset ahead of the time they are requested. The number of elements to prefetch should be equal to (or possibly greater than) the number of batches consumed by a single training step. \n",
        "\n",
        "You could either manually tune this value, or set it to tf.data.experimental.[AUTOTUNE](https://www.tensorflow.org/guide/data_performance) which will prompt the tf.data runtime to tune the value dynamically at runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB0YWp0mvY8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.set_floatx('float32')\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Yq_2wb6V8s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data():\n",
        "  (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "  X_train = X_train/255.0\n",
        "  X_train = np.float32(X_train)\n",
        "  X_test = X_test/255.0\n",
        "  X_test = np.float32(X_test)\n",
        "  \n",
        "  #reshape data to fit model\n",
        "  X_train = X_train.reshape(60000,28,28,1)\n",
        "  X_test = X_test.reshape(10000,28,28,1)\n",
        "  #one-hot encode target column\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  return (X_train, y_train), (X_test, y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl-N6cIL3Tr8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f8b271fa-27b7-40e5-d4f6-af2498749ad1"
      },
      "source": [
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = prepare_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcfJDBjg37oR",
        "colab_type": "code",
        "outputId": "df54bc35-f0d2-483d-8797-5405d32e7654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "#plot the first image in the dataset\n",
        "mon_image = X_train[0].reshape(28,28)\n",
        "mon_image.shape\n",
        "plt.imshow(mon_image)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f3cd6d3ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG4FgHSk_-2P",
        "colab_type": "code",
        "outputId": "9ada17d5-6087-47bc-be63-9fb8ab8639b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "mon_image.dtype"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMM7wQev1kK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28,28,1)),\n",
        "    tf.keras.layers.Conv2D(32, kernel_size=3, activation=\"relu\"),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer='adam', \n",
        "      loss='categorical_crossentropy', \n",
        "      metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTalTAG9uWaF",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"teal\">GPU</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sHrLnnGs-ei",
        "colab_type": "text"
      },
      "source": [
        "En mode TPU, passez directement à la ligne TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE72jzpI51Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjojCqMPD6eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "fd939ec2-15fa-43c9-a59b-7a030beef105"
      },
      "source": [
        "#train the model\n",
        "%%time\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 15s 255us/sample - loss: 0.1249 - accuracy: 0.9619 - val_loss: 0.0469 - val_accuracy: 0.9849\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0436 - val_accuracy: 0.9863\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0476 - val_accuracy: 0.9857\n",
            "CPU times: user 28.5 s, sys: 4.09 s, total: 32.6 s\n",
            "Wall time: 32.3 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb9a02b5e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sz4vDhY-0E2",
        "colab_type": "text"
      },
      "source": [
        "Avec le CPU, on a les résultats suivants : \n",
        "\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "\n",
        "Epoch 1/3\n",
        "60000/60000 [==============================] - 155s 3ms/sample - loss: 0.1294 - accuracy: 0.9610 - val_loss: 0.0544 - val_accuracy: 0.9821\n",
        "\n",
        "Epoch 2/3\n",
        "60000/60000 [==============================] - 154s 3ms/sample - loss: 0.0471 - accuracy: 0.9851 - val_loss: 0.0500 - val_accuracy: 0.9849\n",
        "\n",
        "Epoch 3/3\n",
        "60000/60000 [==============================] - 154s 3ms/sample - loss: 0.0313 - accuracy: 0.9897 - val_loss: 0.0408 - val_accuracy: 0.9871\n",
        "\n",
        "CPU times: user 14min, sys: 14.8 s, total: 14min 15s\n",
        "Wall time: 7min 42s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fPxEFcpv5Da",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"orange\">GPU</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGtznoe7uOzI",
        "colab_type": "text"
      },
      "source": [
        "A partir d'ici on peut recommencer depuis le début avec le mode GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0xDFBw_nCj",
        "colab_type": "text"
      },
      "source": [
        "Avec le GPU on a les temps suivants : \n",
        "\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "\n",
        "Epoch 1/3\n",
        "60000/60000 [==============================] - 13s 220us/sample - loss: 0.2416 - accuracy: 0.9510 - val_loss: 0.0797 - val_accuracy: 0.9743\n",
        "\n",
        "Epoch 2/3\n",
        "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0722 - accuracy: 0.9776 - val_loss: 0.0931 - val_accuracy: 0.9727\n",
        "\n",
        "Epoch 3/3\n",
        "60000/60000 [==============================] - 7s 111us/sample - loss: 0.0505 - accuracy: 0.9845 - val_loss: 0.0836 - val_accuracy: 0.9742\n",
        "\n",
        "CPU times: user 22.5 s, sys: 3.42 s, total: 25.9 s\n",
        "Wall time: 26.6 s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5VzPewRwscf",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-3PWqoMwtqc",
        "colab_type": "text"
      },
      "source": [
        "Le temps d'exécution en mode GPU est, selon les moments, entre 10x et 40x inférieur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T01MJ0l_7Jh",
        "colab_type": "text"
      },
      "source": [
        "On passe de 16mins 47s à 22.5s soit 44 fois moins !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQqHy0kZxDmo",
        "colab_type": "text"
      },
      "source": [
        "## <font color=\"orange\">TPU</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1e72OPpX3Tz",
        "colab_type": "text"
      },
      "source": [
        "Avec les TPU on a (si on ne change rien à la programmation, c'est à dire si on fait comme si on utilisait un GPU, on ne sait d'ailleurs pas ce qui est fait)\n",
        "\n",
        "Train on 60000 samples, validate on 10000 samples\n",
        "\n",
        "Epoch 1/3\n",
        "60000/60000 [==============================] - 183s 3ms/sample - loss: 0.1294 - accuracy: 0.9614 - val_loss: 0.0522 - val_accuracy: 0.9838\n",
        "\n",
        "Epoch 2/3\n",
        "60000/60000 [==============================] - 184s 3ms/sample - loss: 0.0490 - accuracy: 0.9850 - val_loss: 0.0539 - val_accuracy: 0.9825\n",
        "\n",
        "Epoch 3/3\n",
        "60000/60000 [==============================] - 189s 3ms/sample - loss: 0.0331 - accuracy: 0.9900 - val_loss: 0.0429 - val_accuracy: 0.9866\n",
        "\n",
        "CPU times: user 16min 42s, sys: 18.7 s, total: 17min 1s\n",
        "Wall time: 9min 15s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxX7tZZbEOhY",
        "colab_type": "code",
        "outputId": "26c704ce-b8d2-4d24-f38b-855d25241b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "#predict first 4 images in the test set\n",
        "model.predict(X_test[:4])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.3868536e-10, 2.5384984e-11, 7.9467554e-08, 4.8206712e-05,\n",
              "        1.1444599e-10, 1.2426697e-09, 4.1493148e-16, 9.9995100e-01,\n",
              "        2.4035016e-08, 6.8653816e-07],\n",
              "       [4.9192590e-08, 3.4795340e-07, 9.9999952e-01, 1.0834928e-08,\n",
              "        1.6498177e-12, 9.0034917e-11, 1.3534873e-07, 1.6565513e-14,\n",
              "        3.3975418e-08, 1.1672646e-14],\n",
              "       [1.4948826e-06, 9.9404091e-01, 3.0801953e-03, 8.3905064e-07,\n",
              "        9.5109153e-04, 1.8509762e-05, 1.7570300e-06, 5.6205099e-05,\n",
              "        1.8482264e-03, 5.4234800e-07],\n",
              "       [9.9999964e-01, 7.8003638e-11, 2.3971484e-07, 8.3444424e-10,\n",
              "        1.4592913e-10, 7.7540419e-10, 8.1500787e-08, 1.2818511e-09,\n",
              "        1.6225464e-08, 3.1669889e-09]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsrZqiXrJKEn",
        "colab_type": "code",
        "outputId": "76540a24-1330-4338-849d-02fa735a6bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#actual results for first 4 images in test set\n",
        "y_test[:4]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTPEgUjxvRZ7",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"teal\">TPU</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRP-CA8gxMWY",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Mu4HKx6CSJl",
        "colab_type": "text"
      },
      "source": [
        "A partir d'ici, il faut passer en mode TPU. \n",
        "\n",
        "Exécution / Modifier le type d'exécution / TPU\n",
        "\n",
        "Exécution / Redémarrerr l'environnement d'exécution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWxSphllvYaP",
        "colab_type": "text"
      },
      "source": [
        "Réexécutez les imports de début du code + les fonctions jusqu'à la création du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb8Wi5slxO1W",
        "colab_type": "text"
      },
      "source": [
        "Non seulement, on force GCP à utiliser le TPU mais on programme aussi différemment pour prendre en compte les spécificités du TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5hsUvhqGVFu",
        "colab_type": "code",
        "outputId": "2f211a1b-730b-4992-a3bc-198cb2654662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_2kH9zlyK6-",
        "colab_type": "text"
      },
      "source": [
        "Il ne faut pas être en mode eager"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5OS3GBdGg78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN_2fjfgGifR",
        "colab_type": "code",
        "outputId": "a1989e71-d615-4584-f97c-49aff41433ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tf.executing_eagerly()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dyHH5vKyQ5z",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErqVV_9cgkXP",
        "colab_type": "text"
      },
      "source": [
        "[TPUStrategy](https://www.tensorflow.org/guide/distributed_training)\n",
        "\n",
        "tf.distribute.experimental.TPUStrategy lets you run your TensorFlow training on Tensor Processing Units (TPUs). TPUs are Google's specialized ASICs designed to dramatically accelerate machine learning workloads. They are available on Google Colab, the TensorFlow Research Cloud and Cloud TPU.\n",
        "\n",
        "In terms of distributed training architecture, TPUStrategy is the same MirroredStrategy - it implements synchronous distributed training. TPUs provide their own implementation of efficient all-reduce and other collective operations across multiple TPU cores, which are used in TPUStrategy.\n",
        "\n",
        "Here is how you would instantiate TPUStrategy:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3VaRNizySlF",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLsnORkRl5rb",
        "colab_type": "text"
      },
      "source": [
        "Class [TPUClusterResolver](https://www.tensorflow.org/api_docs/python/tf/distribute/cluster_resolver/TPUClusterResolver)\n",
        "\n",
        "This is an implementation of cluster resolvers for the Google Cloud TPU service. As Cloud TPUs are in alpha, you will need to specify a API definition file for this to consume, in addition to a list of Cloud TPUs in your Google Cloud Platform project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkUXAvvByT5H",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5sPFriWm7kh",
        "colab_type": "text"
      },
      "source": [
        "tf.config.[experimental_connect_to_cluster](https://www.tensorflow.org/api_docs/python/tf/config/experimental_connect_to_cluster)\n",
        "\n",
        "Connects to the given cluster.\n",
        "\n",
        "Will make devices on the cluster available to use. Note that calling this more than once will work, but will invalidate any tensor handles on the old remote devices.\n",
        "\n",
        "If the given local job name is not present in the cluster specification, it will be automatically added, using an unused port on the localhost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6x-I6MoyVcS",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGb6F74onSel",
        "colab_type": "text"
      },
      "source": [
        "tf.tpu.experimental.[initialize_tpu_system](https://www.tensorflow.org/api_docs/python/tf/tpu/experimental/initialize_tpu_system)\n",
        "\n",
        "Initialize the TPU devices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb2R-KTaJQTu",
        "colab_type": "code",
        "outputId": "71178ddd-7019-4f3b-d0d0-66a98b7d87e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.70.116.226:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: 10.70.116.226:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.70.116.226:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.70.116.226:8470) for TPU system metadata.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.70.116.226:8470) for TPU system metadata.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1958581413149856773)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1958581413149856773)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12857563142458586554)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12857563142458586554)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7060905907629160575)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7060905907629160575)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11205962453745526484)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 11205962453745526484)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1488161544966279727)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1488161544966279727)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14016660825454483113)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14016660825454483113)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13634079942559876641)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13634079942559876641)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2879509415842815923)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2879509415842815923)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5574702418338226445)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5574702418338226445)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8113252783876224115)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8113252783876224115)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1685068716863653638)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 1685068716863653638)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bs4M2nOhvbq",
        "colab_type": "text"
      },
      "source": [
        "We've integrated tf.distribute.Strategy into tf.keras which is TensorFlow's implementation of the Keras API specification. tf.keras is a high-level API to build and train models. By integrating into tf.keras backend, we've made it seamless for you to distribute your training written in the Keras training framework.\n",
        "\n",
        "Here's what you need to change in your code:\n",
        "\n",
        "- Create an instance of the appropriate tf.distribute.Strategy\n",
        "- Move the creation and compiling of Keras model inside strategy.scope."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuhGZMy313Q3",
        "colab_type": "code",
        "outputId": "4d8dba2c-0dee-46d9-c913-d6651094e35f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "  model = create_model()\n",
        "  model.compile(\n",
        "      optimizer='adam', \n",
        "      loss='categorical_crossentropy', \n",
        "      metrics=['accuracy'])\n",
        "  \n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        18464     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                184330    \n",
            "=================================================================\n",
            "Total params: 203,434\n",
            "Trainable params: 203,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISPbY4kWEpKJ",
        "colab_type": "code",
        "outputId": "02e5e588-b9cc-4d6e-e394-653f65d332c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tpu.num_accelerators()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TPU': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dEQSYIvEwY3",
        "colab_type": "code",
        "outputId": "1386ea34-ed40-4ff1-f698-de57694f4832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tpu.get_master()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'grpc://10.70.116.226:8470'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhoSRIOj2V3O",
        "colab_type": "code",
        "outputId": "712336c3-2eaf-4b57-ec03-275907f7ab80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "%%time\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9625INFO:tensorflow:Running validation at fit epoch: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running validation at fit epoch: 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 19ms/step\n",
            "313/313 [==============================] - 6s 19ms/step\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1245 - accuracy: 0.9625 - val_loss: 0.0571 - val_accuracy: 0.9803\n",
            "Epoch 2/3\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9857INFO:tensorflow:Running validation at fit epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running validation at fit epoch: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 19ms/step\n",
            "313/313 [==============================] - 6s 19ms/step\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0470 - accuracy: 0.9857 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
            "Epoch 3/3\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9907INFO:tensorflow:Running validation at fit epoch: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running validation at fit epoch: 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 6s 20ms/step\n",
            "313/313 [==============================] - 6s 20ms/step\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 0.0476 - val_accuracy: 0.9852\n",
            "CPU times: user 12.9 s, sys: 1.49 s, total: 14.4 s\n",
            "Wall time: 1min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3cd27335f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNf256UMberp",
        "colab_type": "text"
      },
      "source": [
        "On obtient les résultats suivants :\n",
        "\n",
        "Epoch 1/3\n",
        "1873/1875 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9933INFO:tensorflow:Running validation at fit epoch: 0\n",
        "INFO:tensorflow:Running validation at fit epoch: 0\n",
        "\n",
        "313/313 [==============================] - 7s 24ms/step\n",
        "\n",
        "313/313 [==============================] - 7s 24ms/step\n",
        "\n",
        "1875/1875 [==============================] - 21s 11ms/step \n",
        "- loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0574 - val_accuracy: 0.9831\n",
        "\n",
        "Epoch 2/3\n",
        "\n",
        "1867/1875 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9949INFO:tensorflow:Running validation at fit epoch: 1\n",
        "INFO:tensorflow:Running validation at fit epoch: 1\n",
        "\n",
        "313/313 [==============================] - 8s 27ms/step\n",
        "\n",
        "313/313 [==============================] - 8s 27ms/step\n",
        "\n",
        "1875/1875 [==============================] - 22s 12ms/step \n",
        "\n",
        "- loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.0784 - val_accuracy: 0.9794\n",
        "\n",
        "Epoch 3/3\n",
        "\n",
        "1866/1875 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9964INFO:tensorflow:Running validation at fit epoch: 2\n",
        "INFO:tensorflow:Running validation at fit epoch: 2\n",
        "\n",
        "313/313 [==============================] - 9s 30ms/step\n",
        "\n",
        "313/313 [==============================] - 9s 30ms/step\n",
        "\n",
        "1875/1875 [==============================] - 23s 12ms/step \n",
        "\n",
        "- loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.1103 - val_accuracy: 0.9745\n",
        "\n",
        "CPU times: user 12.1 s, sys: 1.09 s, total: 13.2 s\n",
        "Wall time: 1min 17s\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn4pvxkuzVOl",
        "colab_type": "text"
      },
      "source": [
        "[![](https://raw.githubusercontent.com/BackProp-fr/meetup/master/images/LogoBackPropTranspSmall.png)](https://www.backprop.fr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63660GMHzL9G",
        "colab_type": "text"
      },
      "source": [
        "Le temps d'exécution est plus rapide et l'accuracy est meilleure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpYOgvL8Ddui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "e4b4bfff-eb6e-4e64-8d9b-53d7722d5ba6"
      },
      "source": [
        "#predict first 4 images in the test set\n",
        "model.predict(X_test[:4])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.4097126e-11, 6.4637212e-10, 4.7197179e-08, 6.5797344e-08,\n",
              "        4.6406565e-10, 3.8603714e-11, 6.9782763e-17, 9.9999976e-01,\n",
              "        1.4314699e-10, 7.1423983e-08],\n",
              "       [5.1614609e-08, 1.6818255e-07, 9.9979204e-01, 7.9136636e-10,\n",
              "        1.9939832e-10, 1.1113734e-09, 2.0556501e-04, 5.3176376e-14,\n",
              "        2.1223739e-06, 1.1100900e-09],\n",
              "       [1.1973402e-08, 9.9856323e-01, 2.7786166e-04, 3.7105876e-09,\n",
              "        1.1171389e-03, 1.7416945e-06, 2.3968497e-07, 1.3214829e-05,\n",
              "        2.6576450e-05, 2.0295044e-08],\n",
              "       [9.9999797e-01, 1.2556397e-13, 1.6738706e-07, 1.2223725e-12,\n",
              "        2.4853770e-09, 1.0082751e-10, 6.6949667e-07, 3.4069476e-09,\n",
              "        4.9275330e-09, 1.1858571e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWDtvCQa1yB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "227e17fa-bf29-408b-ded4-fdcc51a09708"
      },
      "source": [
        "#actual results for first 4 images in test set\n",
        "y_test[:4]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR9xb-ktb-XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}